{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# #########Q1#########\n",
        "# Load oil.csv. This file contains years worth of data of the daily\n",
        "# oil price. However, the data is missing for a few days. \n",
        "# Make sure that every day contains\n",
        "# a value using any data imputation technique \n",
        "# that you learned during the data preparation\n",
        "# week or during the missing values imputation week\n",
        "\n",
        "# 1. Load the data\n",
        "oil_df = pd.read_csv('oil.csv')\n",
        "\n",
        "# 2. Convert the 'date' column to datetime and set it as index\n",
        "oil_df['date'] = pd.to_datetime(oil_df['date'])\n",
        "oil_df.set_index('date', inplace=True)\n",
        "\n",
        "oil_df.isna().sum()\n",
        "\n",
        "# 3. Perform linear interpolation to fill missing values\n",
        "oil_df_interpolated = oil_df.interpolate(method='linear')\n",
        "\n",
        "# 4. Calculate the mean of the available oil price data excluding NaN values\n",
        "mean_oil_price = oil_df['dcoilwtico'].mean()\n",
        "\n",
        "# 5. Fill initial NaN values with the calculated mean\n",
        "oil_df_interpolated['dcoilwtico'].fillna(mean_oil_price, inplace=True)\n",
        "\n",
        "# Create new file 'oil2.csv' and write interpolated data into it after filling initial NaN values with mean\n",
        "oil_df_interpolated.to_csv('oil2.csv')\n",
        "\n",
        "# oil_df_interpolated.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import preprocessing\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.datasets import load_iris\n",
        "#Note: imports are optional (I used VSCode to do the assignment)\n",
        "#########Q2#########\n",
        "# Augment the data in test.csv and train.csv with the oil price data.\n",
        "# Re-loading the train.csv and test.csv files\n",
        "oil_df_interpolated = pd.read_csv('oil2.csv')\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# Convert the 'date' column in oil_df_interpolated to datetime\n",
        "oil_df_interpolated['date'] = pd.to_datetime(oil_df_interpolated['date'])\n",
        "\n",
        "# Convert the 'date' column in train and test datasets to datetime\n",
        "train_df['date'] = pd.to_datetime(train_df['date'])\n",
        "test_df['date'] = pd.to_datetime(test_df['date'])\n",
        "\n",
        "# Merge train_df and oil_df_interpolated using 'date' as the key column\n",
        "train_augmented = train_df.merge(oil_df_interpolated, left_on='date', right_on='date', how='left')\n",
        "test_augmented = test_df.merge(oil_df_interpolated, left_on='date', right_on='date', how='left')\n",
        "\n",
        "train_augmented.to_csv('train_augmented.csv')\n",
        "test_augmented.to_csv('test_augmented.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import preprocessing\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.datasets import load_iris\n",
        "########Question 3########\n",
        "# Load augmented datasets\n",
        "train_augmented = pd.read_csv('train_augmented.csv')\n",
        "test_augmented = pd.read_csv('test_augmented.csv')\n",
        "train_augmented.drop([\"date\"], axis=1, inplace=True)\n",
        "test_augmented.drop([\"date\"], axis=1, inplace=True)\n",
        "\n",
        "# print(train_augmented.head())\n",
        "\n",
        "# I used a sample of the dataset at first to test with 30%, 70% and then 100% of the values\n",
        "sampled_train_augmented = train_augmented.sample(frac=1, random_state=42)\n",
        "\n",
        "# Basic preprocessing for train and sampled train datasets\n",
        "label_encoder = LabelEncoder()\n",
        "print(sampled_train_augmented.tail())\n",
        "sampled_train_augmented['family'] = label_encoder.fit_transform(sampled_train_augmented['family'])\n",
        "test_augmented['family'] = label_encoder.transform(test_augmented['family'])\n",
        "\n",
        "# Fill missing values with mean\n",
        "# print(sampled_train_augmented.tail()) (used for testing)\n",
        "\n",
        "sampled_train_augmented.fillna(sampled_train_augmented.mean(), inplace=True)\n",
        "test_augmented.fillna(sampled_train_augmented.mean(), inplace=True)\n",
        "\n",
        "# Preparing the data for training\n",
        "features = ['family', 'dcoilwtico']  \n",
        "X = sampled_train_augmented[features]\n",
        "y = sampled_train_augmented['sales']\n",
        "\n",
        "# Split the sampled training data for validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize models\n",
        "lr_model = LinearRegression()\n",
        "rf_model = RandomForestRegressor(n_estimators=10, max_depth=5, min_samples_split=4, min_samples_leaf=2, random_state=42)\n",
        "\n",
        "# Train models\n",
        "lr_model.fit(X_train, y_train)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on validation set\n",
        "lr_pred_val = lr_model.predict(X_val)\n",
        "rf_pred_val = rf_model.predict(X_val)\n",
        "\n",
        "# Calculate and compare MSE\n",
        "lr_mse = mean_squared_error(y_val, lr_pred_val)\n",
        "rf_mse = mean_squared_error(y_val, rf_pred_val)\n",
        "print(type(lr_mse))\n",
        "\n",
        "# Convert MSE to DataFrames\n",
        "lr_mse_df = pd.DataFrame({'Linear Regression MSE': [lr_mse]})\n",
        "rf_mse_df = pd.DataFrame({'Random Forest MSE': [rf_mse]})\n",
        "\n",
        "# Save MSE to CSV files (optional)\n",
        "lr_mse_df.to_csv('lr_mse.csv', index=False)\n",
        "rf_mse_df.to_csv('rf_mse.csv', index=False)\n",
        "\n",
        "# Print the values to console\n",
        "print(\"Linear Regression MSE: \", lr_mse)\n",
        "print(\"Random Forest MSE: \", rf_mse)\n",
        "print(train_augmented.sales.max())\n",
        "print(train_augmented.sales.min())\n",
        "\n",
        "# Predict on test set\n",
        "X_test = test_augmented[features]\n",
        "test_augmented['lr_sales_prediction'] = lr_model.predict(X_test)\n",
        "test_augmented['rf_sales_prediction'] = rf_model.predict(X_test)\n",
        "\n",
        "lr_sales_prediction_df = pd.DataFrame({'lr_sales_prediction': test_augmented['lr_sales_prediction']})\n",
        "rf_sales_prediction_df = pd.DataFrame({'rf_sales_prediction': test_augmented['rf_sales_prediction']})\n",
        "# Save predictions to a CSV file\n",
        "test_augmented[['lr_sales_prediction', 'rf_sales_prediction']].to_csv('predictions_test_augmented.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "########Question 4########\n",
        "# Gotta reconstruct the id column on predictions so that I can merge on this column\n",
        "# NOTE: assumption that the data is perfectly aligned (row wise), which is okay and works\n",
        "test_augmented = pd.read_csv('test_augmented.csv')\n",
        "predictions_test_augmented = pd.read_csv('predictions_test_augmented.csv')\n",
        "predictions_test_augmented['id'] = test_augmented['id']\n",
        "\n",
        "submission = pd.read_csv('submission.csv')\n",
        "\n",
        "# Merge predictions with submission \n",
        "comparison_df = predictions_test_augmented.merge(submission, on='id')\n",
        "\n",
        "print(comparison_df.head())\n",
        "\n",
        "# Function to calculate RMSE\n",
        "def rmse(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "# Function to calculate MAPE\n",
        "# def mape(y_true, y_pred): \n",
        "#     epsilon = 1e-10\n",
        "#     return np.mean(np.abs((y_true - y_pred) / (y_true + epsilon))) * 100\n",
        "# EDIT: MAPE is not a good metric for this problem because there are many 0s in the data...\n",
        "# I tried using a variable to offset and fix the division by 0 (epsilon), but that has weird behaviour (aka extremely high values, meaning  that there are instances where the actual sales (y_true) are very close to zero, which greatly inflates the percentage errors)\n",
        "# So, I instead use Median Absolute Deviation (MedAD) as a third metric (see below)\n",
        "\n",
        "def medad(y_true, y_pred):\n",
        "    return np.median(np.abs(y_true - y_pred))\n",
        "\n",
        "# Calculate MedAD for Linear Regression and Random Forest predictions\n",
        "lr_medad = medad(comparison_df['sales'], comparison_df['lr_sales_prediction'])\n",
        "rf_medad = medad(comparison_df['sales'], comparison_df['rf_sales_prediction'])\n",
        "\n",
        "# Calculate metrics for Linear Regression predictions\n",
        "lr_rmse = rmse(comparison_df['sales'], comparison_df['lr_sales_prediction'])\n",
        "lr_mad = mean_absolute_error(comparison_df['sales'], comparison_df['lr_sales_prediction'])\n",
        "# lr_mape = mape(comparison_df['sales'], comparison_df['lr_sales_prediction'])\n",
        "\n",
        "# Calculate metrics for Random Forest predictions\n",
        "rf_rmse = rmse(comparison_df['sales'], comparison_df['rf_sales_prediction'])\n",
        "rf_mad = mean_absolute_error(comparison_df['sales'], comparison_df['rf_sales_prediction'])\n",
        "# rf_mape = mape(comparison_df['sales'], comparison_df['rf_sales_prediction'])\n",
        "\n",
        "# Print results to console \n",
        "print(f\"Linear Regression - RMSE: {lr_rmse}, MAD: {lr_mad}\")\n",
        "print(f\"Random Forest - RMSE: {rf_rmse}, MAD: {rf_mad}\")\n",
        "print(f\"Linear Regression - MedAD: {lr_medad}\")\n",
        "print(f\"Random Forest - MedAD: {rf_medad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Question 4 Analysis\n",
        "\n",
        "\n",
        "## Question 4, c) \n",
        "\n",
        "### \"Compare the three errors. Are they in agreement? Do you think any of the methods is objectively better than the others in this case?\"\n",
        "\n",
        "I chose to use the MedAD metric as the third metric to compare the models' performance. The MedAD metric is the Median Absolute Deviation between the predicted and actual values. This metric is useful because it is not as sensitive to outliers as the MAPE metric (see comments in q4).\n",
        "\n",
        "Analysis:\n",
        "\n",
        "All three metrics show a **consistent** trend: the Random Forest model has significantly lower errors compared to the Linear Regression model. This consistency across different types of error metrics indicates a strong agreement in their assessment of the models' performance.\n",
        "\n",
        "**The RFM is a better model** for this case because it has lower errors across all three metrics (RMSE, MAD, and MedAD), indicating that it is better at predicting the actual values of the data points. \n",
        "- A lower RMSE indicates that it is better at handling larger deviations in predictions. \n",
        "- A lower MAD indicates that, on average, it makes smaller errors than the Linear Regression model. \n",
        "- A lower MedAD, which indicates that the median size of errors is much smaller, indicating more consistent and accurate predictions for the majority of the data points.\n",
        "_____\n",
        "\n",
        "Interpretation of the errors:\n",
        "\n",
        "- RMSE: It emphasizes larger errors more due to the squaring of the residuals. The fact that RF has a substantially lower RMSE suggests it's better at handling larger deviations in predictions.\n",
        "- MAD: This metric gives an average level of error and is less sensitive to outliers than RMSE. The lower MAD for the Random Forest model indicates that on average, it makes smaller errors than the Linear Regression model.\n",
        "- MedAD: This metric gives the typical or median error in the predictions and is robust to outliers. The significantly lower MedAD for the Random Forest model suggests that the median size of errors is much smaller, indicating more consistent and accurate predictions for the majority of the data points."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "name": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
